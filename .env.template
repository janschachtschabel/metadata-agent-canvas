# ===========================
# LLM Provider Configuration
# ===========================
# Kopieren Sie diese Datei zu .env und fügen Sie Ihre echten API-Keys ein
# .env ist in .gitignore und wird NICHT ins Repository committed!

# LLM Provider Selection (Optional)
# Options: openai, b-api-openai, b-api-academiccloud
# Default: b-api-openai
# - openai: Direct OpenAI API (requires OPENAI_API_KEY)
# - b-api-openai: B-API OpenAI-compatible endpoint (requires B_API_KEY)
# - b-api-academiccloud: B-API AcademicCloud with DeepSeek-R1 (requires B_API_KEY)
LLM_PROVIDER=b-api-openai

# OpenAI API Key (Required if LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# B-API Key (Required if LLM_PROVIDER=b-api-openai or b-api-academiccloud)
B_API_KEY=

# OpenAI API Base URL (Optional)
# Useful for proxies or custom endpoints
# Default: https://api.openai.com/v1
OPENAI_BASE_URL=

# OpenAI Model (Optional)
# Default: gpt-4.1-mini
# Options: gpt-5-mini, gpt-5-nano, gpt-5, gpt-4.1-mini, gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo, etc.
OPENAI_MODEL=gpt-4.1-mini

# ===========================
# GPT-5 Performance Settings
# ===========================
# ⚠️ NOTE: These parameters are ONLY used when OPENAI_MODEL starts with "gpt-5"
# For other models (gpt-4, gpt-3.5, etc.), these settings are ignored.

# Reasoning Effort (Optional - GPT-5 only)
# Controls how much "thinking time" GPT-5 invests
# Default: minimal
# Options: minimal, low, medium, high
# - minimal: Fast extraction (~0.5-1s per call) - Recommended for structured data
# - low: Better quality (~1-2s per call)
# - medium: High quality (~2-3s per call)
# - high: Maximum quality (~3-5s per call)
GPT5_REASONING_EFFORT=minimal

# Response Verbosity (Optional - GPT-5 only)
# Controls the length of responses
# Default: low
# Options: low, medium, high
# - low: Concise, minimal tokens - Recommended for extraction
# - medium: Balanced responses
# - high: Detailed, verbose responses
GPT5_VERBOSITY=low
