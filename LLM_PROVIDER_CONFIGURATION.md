# LLM Provider Configuration

Die App unterst√ºtzt mehrere OpenAI-kompatible LLM-Provider. Zwischen den Providern kann √ºber die Environment-Konfiguration gewechselt werden.

## Unterst√ºtzte Provider

### 1. OpenAI (Standard)
- **Provider-ID:** `openai`
- **Base URL:** `https://api.openai.com/v1`
- **Authentifizierung:** Bearer Token (Authorization Header)
- **Environment Variable:** `OPENAI_API_KEY`

### 2. Provider B (OpenEduHub)
- **Provider-ID:** `provider-b`
- **Base URL:** `https://b-api.staging.openeduhub.net/api/v1/llm/openai`
- **Authentifizierung:** Custom Header (`X-API-KEY`)
- **Environment Variable:** `B_API_KEY`

---

## Lokale Entwicklung (Development Mode)

### Environment-Konfiguration

**Datei:** `src/environments/environment.ts`

```typescript
export const environment = {
  production: false,
  
  // Provider ausw√§hlen: 'openai' oder 'provider-b'
  llmProvider: 'openai',
  
  // OpenAI Configuration
  openai: {
    apiKey: 'sk-proj-...', // Dein OpenAI API Key
    baseUrl: '', // Leer lassen f√ºr Standard-URL
    model: 'gpt-4.1-mini',
    temperature: 0.3
  },
  
  // Provider B Configuration
  providerB: {
    apiKey: 'bb6cdf84-...', // Dein Provider B API Key
    baseUrl: 'https://b-api.staging.openeduhub.net/api/v1/llm/openai',
    model: 'gpt-4.1-mini',
    temperature: 0.3,
    requiresCustomHeader: true // Wichtig f√ºr X-API-KEY Header
  }
};
```

### Provider wechseln

√Ñndere einfach `llmProvider` in `environment.ts`:

```typescript
// OpenAI verwenden
llmProvider: 'openai',

// ODER Provider B verwenden
llmProvider: 'provider-b',
```

---

## Production (Netlify)

### Environment Variables konfigurieren

**Netlify Dashboard ‚Üí Site Settings ‚Üí Environment Variables**

F√ºge folgende Variablen hinzu:

```bash
# F√ºr OpenAI
OPENAI_API_KEY=sk-proj-...

# F√ºr Provider B
B_API_KEY=bb6cdf84-0a9d-47f3-b673-c1b4f25b9bdc
```

### Provider wechseln

**Option 1: Build-Zeit-Konfiguration**

√Ñndere `llmProvider` in `src/environments/environment.prod.ts`:

```typescript
llmProvider: 'provider-b',
```

**Option 2: Environment Variable (geplant)**

Zuk√ºnftig k√∂nnte auch eine ENV-Variable genutzt werden:
```bash
LLM_PROVIDER=provider-b
```

---

## API-Unterschiede

### OpenAI
```javascript
// Request Headers
{
  'Content-Type': 'application/json',
  'Authorization': 'Bearer sk-proj-...'
}

// API Endpoint
POST https://api.openai.com/v1/chat/completions
```

### Provider B
```javascript
// Request Headers
{
  'Content-Type': 'application/json',
  'X-API-KEY': 'bb6cdf84-0a9d-47f3-b673-c1b4f25b9bdc'
}

// API Endpoint
POST https://b-api.staging.openeduhub.net/api/v1/llm/openai/chat/completions
```

**Python-Beispiel f√ºr Provider B:**
```python
from openai import OpenAI

client = OpenAI(
    api_key="bb6cdf84-0a9d-47f3-b673-c1b4f25b9bdc",
    base_url="https://b-api.staging.openeduhub.net/api/v1/llm/openai",
    default_headers={"X-API-KEY": "bb6cdf84-0a9d-47f3-b673-c1b4f25b9bdc"}
)

response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role": "user", "content": "Hallo!"}]
)
```

---

## Architektur

### Development Mode (Lokal)

```
Browser
  ‚Üì
openai-proxy.service.ts (Angular)
  ‚Üì
[Provider-Auswahl basierend auf llmProvider]
  ‚Üì
‚îú‚îÄ openai ‚Üí https://api.openai.com/v1/chat/completions
‚îÇ             Header: Authorization: Bearer <OPENAI_API_KEY>
‚îÇ
‚îî‚îÄ provider-b ‚Üí https://b-api.staging.openeduhub.net/api/v1/llm/openai/chat/completions
                Header: X-API-KEY: <B_API_KEY>
```

### Production Mode (Netlify)

```
Browser
  ‚Üì
openai-proxy.service.ts (Angular)
  ‚Üì
Netlify Function (/.netlify/functions/openai-proxy)
  ‚Üì [provider=openai/provider-b]
  ‚Üì
‚îú‚îÄ openai ‚Üí https://api.openai.com/v1/chat/completions
‚îÇ             Header: Authorization: Bearer <OPENAI_API_KEY>
‚îÇ             ENV: OPENAI_API_KEY
‚îÇ
‚îî‚îÄ provider-b ‚Üí https://b-api.staging.openeduhub.net/api/v1/llm/openai/chat/completions
                Header: X-API-KEY: <B_API_KEY>
                ENV: B_API_KEY
```

---

## Fehlerbehandlung

Beide Provider nutzen das **gleiche Retry-System**:
- **Max. 3 Retries** bei transienten Fehlern (402, 429, 500, 502, 503, 504)
- **Exponential Backoff** mit Jitter (1s ‚Üí 2s ‚Üí 4s)
- **Automatic Failover** bei Netzwerkfehlern

---

## Weitere Provider hinzuf√ºgen

Um einen weiteren Provider (z.B. `provider-c`) hinzuzuf√ºgen:

1. **Environment erweitern** (`environment.ts`, `environment.prod.ts`):
   ```typescript
   providerC: {
     apiKey: '',
     baseUrl: 'https://api.provider-c.com',
     model: 'gpt-4.1-mini',
     temperature: 0.3,
     requiresCustomHeader: false // oder true
   }
   ```

2. **Service erweitern** (`openai-proxy.service.ts`):
   ```typescript
   this.providerConfig = this.provider === 'provider-c' 
     ? (environment as any).providerC 
     : ...
   ```

3. **Netlify Function erweitern** (`netlify/functions/openai-proxy.js`):
   ```javascript
   if (selectedProvider === 'provider-c') {
     apiKey = process.env.C_API_KEY;
     baseUrl = 'https://api.provider-c.com';
     requiresCustomHeader = false;
   }
   ```

4. **Environment Variable auf Netlify setzen**:
   ```
   C_API_KEY=...
   ```

---

## Tests

### Provider-Wechsel testen

```bash
# Provider B aktivieren
# √Ñndere in environment.ts: llmProvider: 'provider-b'

# App neu starten
npm start

# Console pr√ºfen:
# "üîß Development mode: Using direct PROVIDER-B API access"
# "üåê Base URL: https://b-api.staging.openeduhub.net/api/v1/llm/openai"
```

### API-Call verifizieren

√ñffne Browser DevTools ‚Üí Network Tab:
- **OpenAI:** Request zu `api.openai.com` mit `Authorization: Bearer ...`
- **Provider B:** Request zu `b-api.staging.openeduhub.net` mit `X-API-KEY: ...`

---

## Troubleshooting

### "API key not configured"

**Lokal:**
- Pr√ºfe `environment.ts` ‚Üí `providerB.apiKey` ist gesetzt
- Pr√ºfe `llmProvider: 'provider-b'` ist korrekt

**Netlify:**
- Pr√ºfe Environment Variables ‚Üí `B_API_KEY` ist gesetzt
- Pr√ºfe `environment.prod.ts` ‚Üí `llmProvider: 'provider-b'`

### "CORS error"

**Provider B:**
- Stelle sicher, dass die Base URL korrekt ist
- Pr√ºfe, ob `requiresCustomHeader: true` gesetzt ist

### "Unauthorized"

**OpenAI:**
- API Key ist ung√ºltig oder abgelaufen
- Check: `OPENAI_API_KEY` ENV variable

**Provider B:**
- API Key ist ung√ºltig
- Check: `B_API_KEY` ENV variable
- Check: `X-API-KEY` Header wird gesendet

---

**Stand:** 15. Oktober 2025
